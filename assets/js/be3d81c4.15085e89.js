"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[3833],{7:(e,n,t)=>{t.d(n,{A:()=>a});t(6672);var i=t(3526);const s={tabItem:"tabItem__pw4"};var r=t(3420);function a({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,i.A)(s.tabItem,t),hidden:n,children:e})}},1519:(e,n,t)=>{t.d(n,{A:()=>A});var i=t(6672),s=t(3526),r=t(880),a=t(5291),o=t(7387),l=t(1981),c=t(2962),d=t(621);function u(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return u(e).map((({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i})))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function m({value:e,tabValues:n}){return n.some((n=>n.value===e))}function x({queryString:e=!1,groupId:n}){const t=(0,a.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(s),(0,i.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(t.location.search);n.set(s,e),t.replace({...t.location,search:n.toString()})}),[s,t])]}function p(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,r=h(e),[a,l]=(0,i.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find((e=>e.default))??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:r}))),[c,u]=x({queryString:t,groupId:s}),[p,j]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,d.Dv)(n);return[t,(0,i.useCallback)((e=>{n&&s.set(e)}),[n,s])]}({groupId:s}),g=(()=>{const e=c??p;return m({value:e,tabValues:r})?e:null})();(0,o.A)((()=>{g&&l(g)}),[g]);return{selectedValue:a,selectValue:(0,i.useCallback)((e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),j(e)}),[u,j,r]),tabValues:r}}var j=t(2521);const g={tabList:"tabList_MPh5",tabItem:"tabItem_WAIp"};var f=t(3420);function b({className:e,block:n,selectedValue:t,selectValue:i,tabValues:a}){const o=[],{blockElementScrollPositionUntilNextRender:l}=(0,r.a_)(),c=e=>{const n=e.currentTarget,s=o.indexOf(n),r=a[s].value;r!==t&&(l(n),i(r))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:a.map((({value:e,label:n,attributes:i})=>(0,f.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:d,onClick:c,...i,className:(0,s.A)("tabs__item",g.tabItem,i?.className,{"tabs__item--active":t===e}),children:n??e},e)))})}function v({lazy:e,children:n,selectedValue:t}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find((e=>e.props.value===t));return e?(0,i.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:r.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t})))})}function y(e){const n=p(e);return(0,f.jsxs)("div",{className:(0,s.A)("tabs-container",g.tabList),children:[(0,f.jsx)(b,{...n,...e}),(0,f.jsx)(v,{...n,...e})]})}function A(e){const n=(0,j.A)();return(0,f.jsx)(y,{...e,children:u(e.children)},String(n))}},2433:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"education/prompt-engineering/agents","title":"Agents","description":"Agents","source":"@site/docs/education/01-prompt-engineering/05-agents.mdx","sourceDirName":"education/01-prompt-engineering","slug":"/education/prompt-engineering/agents","permalink":"/vibe-labs/docs/education/prompt-engineering/agents","draft":false,"unlisted":false,"editUrl":"https://github.com/EliFuzz/vibe-labs/docs/education/01-prompt-engineering/05-agents.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Agents","description":"Agents","hide_table_of_contents":true},"sidebar":"education","previous":{"title":"Risks","permalink":"/vibe-labs/docs/education/prompt-engineering/risks"},"next":{"title":"MCP","permalink":"/vibe-labs/docs/education/prompt-engineering/mcp"}}');var s=t(3420),r=t(8906),a=t(7),o=t(1519);const l={title:"Agents",description:"Agents",hide_table_of_contents:!0},c="Agents",d={},u=[];function h(e){const n={h1:"h1",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"agents",children:"Agents"})}),"\n",(0,s.jsxs)(o.A,{queryString:"primary",children:[(0,s.jsxs)(a.A,{value:"definition",label:"Definition",children:[(0,s.jsx)(n.p,{children:"AI Agent - is a software program that uses artificial intelligence to autonomously interact with its environment and achieve specific goals set by a user or another system. These agents can process information, learn from experience, and make decisions to perform tasks on behalf of a user."}),(0,s.jsx)(n.mermaid,{value:"graph LR\n    subgraph Tools\n        api(API call)\n        web(Access Internet)\n        code(Interprete Code)\n    end\n\n    user(User) ---\x3e autonomousAction(Autonomous Action)\n    agent(AI Agent) --\x3e autonomousAction\n    agent ---\x3e|access| memory(Memory)\n    agent ---\x3e reactivity(Reactivity)\n    reactivity --\x3e env(Environment)\n    agent ---\x3e delegateTasks(Delegate Tasks)\n    agent ---\x3e Tools"}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Characteristics"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Autonomy"}),": operates independently for efficient task performance in unpredictable environments"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Reactivity"}),": perceives environmental changes and responds in real-time to handle dynamic situations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Proactivity"}),": exhibits goal-directed behavior with initiative, planning, and strategic execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Social Ability"}),": designed for collaboration and communication with agents or humans, essential for multi-agent systems"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Learning Capabilities"}),": improves performance by learning from experiences and adjusting strategies for continuous adaptation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Goal-Orientation"}),": driven by specific objectives, ensuring purposeful actions contribute to predefined outcomes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Rationality"}),": makes decisions to maximize performance by processing information and selecting optimal approaches"]}),"\n"]})]}),(0,s.jsx)(a.A,{value:"comparison",label:"Comparison",children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Aspect"}),(0,s.jsx)("th",{children:"Bot"}),(0,s.jsx)("th",{children:"AI Assistant"}),(0,s.jsx)("th",{children:"AI Agent"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Purpose"})}),(0,s.jsx)("td",{children:"Automating simple tasks or conversations"}),(0,s.jsx)("td",{children:"Assisting users with tasks"}),(0,s.jsx)("td",{children:"Autonomously and proactively perform complex, multi-step tasks"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Capabilities"})}),(0,s.jsx)("td",{children:"Follows pre-defined rules; limited learning; basic interactions"}),(0,s.jsx)("td",{children:"Responds to requests or prompts; provides information and completes simple tasks; can recommend actions but the user makes decisions"}),(0,s.jsx)("td",{children:"Can perform complex, multi-step actions; learns and adapts; can make decisions independently"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Autonomy Level"})}),(0,s.jsx)("td",{children:"Least autonomous; typically follows pre-programmed rules"}),(0,s.jsx)("td",{children:"Less autonomous; requires user input and direction"}),(0,s.jsx)("td",{children:"Highest degree of autonomy; operates independently to achieve a goal"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Complexity"})}),(0,s.jsx)("td",{children:"Suited for simpler tasks and interactions"}),(0,s.jsx)("td",{children:"Better suited for simpler tasks and interactions"}),(0,s.jsx)("td",{children:"Designed to handle complex tasks and workflows"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Learning Ability"})}),(0,s.jsx)("td",{children:"Limited or no learning"}),(0,s.jsx)("td",{children:"May have some learning capabilities"}),(0,s.jsx)("td",{children:"Often employs machine learning to adapt and improve performance over time"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Interaction Style"})}),(0,s.jsx)("td",{children:"Reactive; responds to triggers or commands"}),(0,s.jsx)("td",{children:"Reactive; responds to user requests"}),(0,s.jsx)("td",{children:"Proactive; goal-oriented"})]})]})]})}),(0,s.jsx)(a.A,{value:"types",label:"Types",children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Type"}),(0,s.jsx)("th",{children:"Definition"}),(0,s.jsx)("th",{children:"How it Works"}),(0,s.jsx)("th",{children:"Key Characteristics"}),(0,s.jsx)("th",{children:"Limitations"}),(0,s.jsx)("th",{children:"Examples"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Simple Reflex Agents"})}),(0,s.jsx)("td",{children:"Respond directly to current environment state without memory"}),(0,s.jsx)("td",{children:'Follows "if-then" rules based on immediate inputs'}),(0,s.jsx)("td",{children:"Quick, efficient for straightforward tasks; minimal computational resources"}),(0,s.jsx)("td",{children:"Limited adaptability; cannot learn or improve; struggles with complex scenarios"}),(0,s.jsx)("td",{children:"Thermostats, basic game bots, simple chatbots"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Model-Based Reflex Agents"})}),(0,s.jsx)("td",{children:"Maintains internal model of environment to predict future states"}),(0,s.jsx)("td",{children:"Uses internal model to understand effects of actions over time and make informed decisions"}),(0,s.jsx)("td",{children:"Better for dynamic environments; can predict future states; more adaptable; handles incomplete info"}),(0,s.jsx)("td",{children:"Increased complexity and computational needs; limited by model accuracy"}),(0,s.jsx)("td",{children:"Self-driving cars, home automation systems, autonomous drones"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Goal-Based Agents"})}),(0,s.jsx)("td",{children:"Designed to achieve specific objectives, evaluating actions based on goal proximity"}),(0,s.jsx)("td",{children:"Evaluates potential outcomes of actions to determine best path to a predefined goal"}),(0,s.jsx)("td",{children:"Highly adaptable; strategic decision-making; handles wide range of tasks"}),(0,s.jsx)("td",{children:"More complex; requires planning and evaluating future actions"}),(0,s.jsx)("td",{children:"Virtual assistants (Siri, Alexa), industrial assembly robots"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Utility-Based Agents"})}),(0,s.jsx)("td",{children:"Maximizes a specific utility function (e.g., profit, satisfaction) rather than just a goal"}),(0,s.jsx)("td",{children:"Evaluates desirability of different outcomes using a utility function to choose optimal actions"}),(0,s.jsx)("td",{children:"Complex decision-making with trade-offs; functions in uncertain environments; finds optimal solutions"}),(0,s.jsx)("td",{children:"Requires carefully designed utility function; computationally intensive"}),(0,s.jsx)("td",{children:"Investment algorithms, navigation route optimizers"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Learning Agents"})}),(0,s.jsx)("td",{children:"Improves performance over time by learning from environmental interactions and experiences"}),(0,s.jsx)("td",{children:"Adapts behavior based on feedback; continuously refines decision-making"}),(0,s.jsx)("td",{children:"Highly adaptable; continuous improvement; discovers novel solutions"}),(0,s.jsx)("td",{children:"Requires large data/feedback; can be computationally intensive"}),(0,s.jsx)("td",{children:"Customer service chatbots, autonomous vehicles"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Multi-Agent Systems (MAS)"})}),(0,s.jsx)("td",{children:"Multiple autonomous agents interact and collaborate for shared/individual goals"}),(0,s.jsx)("td",{children:"Agents communicate, coordinate, and collaborate, often with checks and balances"}),(0,s.jsx)("td",{children:"Organized structure for complex ops; better resource allocation; efficient; robust; scalable"}),(0,s.jsx)("td",{children:"Complex coordination; potential for conflicts"}),(0,s.jsx)("td",{children:"Swarm robotics, smart traffic lights, supply chain management"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Hierarchical Agents"})}),(0,s.jsx)("td",{children:"Master agent coordinates subordinate agents for specific functions"}),(0,s.jsx)("td",{children:"Master agent delegates tasks and makes high-level decisions; subordinates execute"}),(0,s.jsx)("td",{children:"Simplifies complex operations; better resource allocation and task division"}),(0,s.jsx)("td",{children:"Can be rigid; requires effective communication between levels"}),(0,s.jsx)("td",{children:"Orchestrator-specialist systems in complex tasks"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Physical Agents"})}),(0,s.jsx)("td",{children:"Interact with the physical world"}),(0,s.jsx)("td",{children:"Use sensors to perceive and actuators to perform physical actions"}),(0,s.jsx)("td",{children:"Direct manipulation of physical environments"}),(0,s.jsx)("td",{children:"Hardware integration challenges; safety concerns"}),(0,s.jsx)("td",{children:"Smart manufacturing robots"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Software-based Agents"})}),(0,s.jsx)("td",{children:"Operate entirely in digital environments"}),(0,s.jsx)("td",{children:"Interact with users, applications, or online data sources via digital means (APIs, databases)"}),(0,s.jsx)("td",{children:"Efficient for digital tasks; no physical constraints"}),(0,s.jsx)("td",{children:"Limited to digital interactions"}),(0,s.jsx)("td",{children:"Chatbots, virtual assistants, data analysis agents"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Hybrid Agents"})}),(0,s.jsx)("td",{children:"Combine capabilities of software-based and physical agents"}),(0,s.jsx)("td",{children:"Continuously learn from both digital and physical interactions, processing multi-modal data"}),(0,s.jsx)("td",{children:"Seamless integration with real world; adaptive to complex environments"}),(0,s.jsx)("td",{children:"Increased complexity in design and integration"}),(0,s.jsx)("td",{children:"Autonomous vehicles (physical & digital data fusion)"})]})]})]})}),(0,s.jsx)(a.A,{value:"architectural-paradigms",label:"Architectural Paradigms",children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Type"}),(0,s.jsx)("th",{children:"Core Principle"}),(0,s.jsx)("th",{children:"Advantages"}),(0,s.jsx)("th",{children:"Limitations"}),(0,s.jsx)("th",{children:"Use Cases"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Reactive Architectures"})}),(0,s.jsx)("td",{children:"Direct stimulus-response; no internal model or memory"}),(0,s.jsx)("td",{children:"Fast, efficient, simple, resilient due to component decoupling"}),(0,s.jsx)("td",{children:"Cannot learn from past; no future planning; struggles with novel situations"}),(0,s.jsx)("td",{children:"Thermostats, basic game AI, simple chatbots"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Deliberative Architectures"})}),(0,s.jsx)("td",{children:"Internal model of world; reasoning and planning about future"}),(0,s.jsx)("td",{children:"Complex decision-making, reasoning, long-term planning"}),(0,s.jsx)("td",{children:"Slower due to extensive computation; increased complexity"}),(0,s.jsx)("td",{children:"Robotic warehouse pickers, complex planning systems"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Hybrid Architectures"})}),(0,s.jsx)("td",{children:"Combines reactive (quick response) and deliberative (planning) components"}),(0,s.jsx)("td",{children:"Balances immediate reactions with long-term planning; adaptable; efficient resource allocation"}),(0,s.jsx)("td",{children:"Increased complexity in design and integration"}),(0,s.jsx)("td",{children:"Self-driving cars, rescue robots, autonomous underwater vehicles"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"BDI Architecture"})}),(0,s.jsx)("td",{children:"Models human practical reasoning: Beliefs, Desires, Intentions"}),(0,s.jsx)("td",{children:"Mimics human-like decision-making; clear goal-oriented behavior"}),(0,s.jsx)("td",{children:"Can be complex to implement; managing conflicting desires"}),(0,s.jsx)("td",{children:"Intelligent assistants, autonomous planning systems"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("b",{children:"Layered Architectures"})}),(0,s.jsx)("td",{children:"Divides processing into hierarchical levels (e.g., reactive, deliberative)"}),(0,s.jsx)("td",{children:"Clear separation of concerns; easier debugging, scaling, maintenance"}),(0,s.jsx)("td",{children:"Can be rigid if communication between layers is poorly designed"}),(0,s.jsx)("td",{children:"AI-powered cybersecurity systems, complex automation"})]})]})]})})]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},8906:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6672);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);